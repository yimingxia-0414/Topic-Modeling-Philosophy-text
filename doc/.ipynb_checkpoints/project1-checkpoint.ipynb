{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install and load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lib.functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a675f2333219>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# from third libraries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlemmatized_sentence\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mplot_wordcloud\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgenerate_topics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'lib.functions'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import ast\n",
    "pd.set_option('display.max_rows',None)\n",
    "pd.set_option('display.max_columns',None)\n",
    "pd.set_option('max_colwidth',100)\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\" \n",
    "\n",
    "\n",
    "from ipywidgets import widgets, interact, interactive, fixed\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import copy\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# from third libraries\n",
    "from lib.functions import lemmatized_sentence,plot_wordcloud,generate_topics\n",
    "\n",
    "import nltk\n",
    "# nltk.download('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A literal study of philosophical works is necessary. Philosophical language is very abstract, but if you extract words from text and then observe and study them, you can draw many interesting conclusions. The philosophical issues studied by different schools and the philosophical fields studied by different philosophers may have commonalities as well as differences. Data analysis of text is the focus of this article. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data from Kaggle: History of Philosophy (https://www.kaggle.com/kouroshalizadeh/history-of-philosophy) and take a look at the dimention and structure of dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/xiayiming/Desktop/philosophy_data.csv',encoding=\"UTF-8\")\n",
    "df.info()\n",
    "df['title'].nunique()\n",
    "df['author'].nunique()\n",
    "df['school'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we may see, the dataset contains 360808 rows and 11 columns. Variables $original\\_publication\\_date$, $corpus\\_edition\\_date$, $sentence\\_length$ are integer, while the rest of variables are object. No null values are detected. Moreover, the dataset contains 59 different books written by 36 authors from 13 distinct schools.\n",
    "\n",
    "## Text Processing - NLP\n",
    "\n",
    "More information can be extracted after NLP for variable $tokenized\\_txt$ by eliminating stop words and lemmatize sentences using function 'lemmatized_sentence'. The lemmatized sentences are stored in variable $lemmatized\\_str$ and the lengths for those sentences are stored in variable $lemmatized\\_str\\_len$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"lemmatized_str\"] = df[\"tokenized_txt\"].apply(\n",
    "    lambda x: lemmatized_sentence(ast.literal_eval(x))\n",
    ")\n",
    "df[\"lemmatized_str_len\"] = df[\"lemmatized_str\"].apply(\n",
    "    lambda x: len(x.split(\" \"))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To process exploration for data, take a brief view over the data. I will only pick variables $title$, $author$, $school$, $original\\_publication\\_date$, $sentence\\_length$, $sentence\\_lowered$, $tokenized\\_txt$, for exploratory data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[['title','author','school','original_publication_date','sentence_length','sentence_lowered','tokenized_txt']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "some questions might be listed for better overviewing the dataset.\n",
    "\n",
    "1. Which school has the most amount of titles in the dataset?\n",
    "2. Which author is most productive?(with most titles and sentences)\n",
    "3. which title(book) has the most sentences in this dataset? Are the sentences distributed as normal?\n",
    "4. How many sentences per school? Is the amount of titles per school positively correlated to the amount of sentences per school?\n",
    "5. What is the average length of sentence per title? Is it correlated to the amount of sentences per title?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "Use plots and statistical analysis for answering the part1 problems and generate conclusions.\n",
    "\n",
    "### Plots and tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#problem1\n",
    "# Change seaborn plot size\n",
    "# fig = plt.gcf()\n",
    "# fig.set_size_inches(8, 15)\n",
    "\n",
    "df.groupby('school')['title'].nunique().sort_values(ascending=False).plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#problem2\n",
    "df.groupby('author')['title'].nunique().sort_values(ascending=False).head()\n",
    "df.groupby('author')['title'].count().sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#problem3\n",
    "df_1=df.groupby('title')['title'].count().sort_values(ascending=False).to_frame(name='count').reset_index()\n",
    "df_1.head()\n",
    "plt.hist(df_1['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#problem4\n",
    "df_2=df.groupby('school')['title'].count().to_frame(name='n_sentence').reset_index()\n",
    "a_1=df.groupby('school')['title'].nunique()\n",
    "df_2['n_title']=a_1.tolist()\n",
    "\n",
    "df_2.head()\n",
    "plt.scatter(df_2['n_sentence'],df_2['n_title'])\n",
    "np.corrcoef(df_2['n_sentence'],df_2['n_title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#problem5\n",
    "df_3=df.groupby(['title'])['title'].count().to_frame(name='n_sentence').reset_index()\n",
    "df_4=df.groupby('title').mean()\n",
    "df_3['mean_sentence_length']=df_4['sentence_length'].tolist()\n",
    "\n",
    "df_3.head()\n",
    "plt.scatter(df_3['n_sentence'],df_3['mean_sentence_length'])\n",
    "np.corrcoef(df_3['n_sentence'],df_3['mean_sentence_length'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "Problem1:\n",
    "As shown above, Analytic has the most amount of works, beginning around the turn of the 20th century in the contemporary era. This may show that the main focus in the research of philosophy was focusing heavily on that at that particular period. However, Communism, Capitalism, Feminism and Empiricism have relatively equal amount of works with no apparent different.\n",
    "\n",
    "Problem2:\n",
    "I list the top 5 for analysizing Problem2. Nietzsche has 5 titles in the dataset while Aristotle has 48779 sentences. Hegel and Foucault both appeared in the two tables, having same amount of titles and ralatively large amount of sentences.\n",
    "\n",
    "Problem3:\n",
    "Aristotle - Complete Works has the most amount of sentences and Plato - Complete Works is in rank 2. The amount of sentences per title does not distributed normally.\n",
    "\n",
    "Problem4:\n",
    "There is no apparent correlation between the amount of titles per school and the amount of sentences per school.\n",
    "\n",
    "Problem5:\n",
    "There is no apparent correlation between the average length of sentence per title and the amount of sentences per title."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3\n",
    "### Timeline figure and more insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=df.groupby(by=['original_publication_date','school'])['title'].nunique().to_frame(name='count').reset_index()\n",
    "\n",
    "#visualization of 'temp'\n",
    "fig = plt.gcf()\n",
    "# Change seaborn plot size\n",
    "fig.set_size_inches(24, 8)\n",
    "\n",
    "sns.barplot(y='count',x='original_publication_date',hue='school',data=temp)\n",
    "ticks=plt.xticks(rotation='70')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the timeline showing the amount of works classified by schools at different time spots.\n",
    "\n",
    "It starts from early 350 B.C. and lasts to late 20th century. The data does not contain much works for the medieval peroid. During Renaissance of the 15th and 16th centuries heralded the beginning of the modern period, a lot more schools took place by the various colors showing up in the figure.\n",
    "\n",
    "As we may also observe, in 1888, 3 books from nietzsche were published. Nietzsche was productive at that specific year. From certain color continuous showing up on the timeline, we can also notice that there were obvious trends for some schools to be popular for a period of time. For instance, from 1781 to 1820, German\\_idealism had been continuously publishing books. Similarly, Analytics showed the first work in 1910 and kept showing up from time to time, even till year 1985."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Mining\n",
    "\n",
    "## Part 1 Wordcloud\n",
    "\n",
    "### Question: What are the heated topics per school? Do they share similar thoughts or not?\n",
    "\n",
    "### An Overall Wordcloud Inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "schools = df[\"school\"].unique()\n",
    "for school in schools:\n",
    "    plot_wordcloud(\n",
    "        school,\n",
    "        50\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Findings\n",
    "\n",
    "From the wordclouds, some schools which might be abstract to us can be explored more specific due to the words shown in the wordclouds. For example, word 'socrates' appears more often in Plato, since Plato is the famous student of Socrates. As for Aristotle, it focus more on definition, unity and moreover, animals. Analytic discusses more about dream and psychology.\n",
    "\n",
    "The focus of some schools can be predicted based on the definiton itself. For instance, the themes of Feminism, many of which were about the power status of women in education, reading, and work These are still very popular debate topics at present. Stoicism no doubt consists of debates about power, words and desire. Capitalism talks a lot about labour, nation and produce while Communism pays attentions on society, state, commodity. Empiricism makes more efforts on people, with a research on paper work for truth. Rationalism focuses most on thoughts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute TF-IDF Weighted Document-Term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for school in schools:\n",
    "    test=df.loc[df[\"school\"] == school]\n",
    "    t=nltk.word_tokenize(test['lemmatized_str'].str.cat(sep=' '))\n",
    "    result = tfidf.fit_transform(t)\n",
    "    df_5=pd.DataFrame({'word_name':tfidf.get_feature_names(), 'idf':tfidf.idf_})\n",
    "    df_5.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive visualizations on Important Words in Schools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below gives us an interaction over wordclouds and the maximum of words of wordclouds can be choosen as 20, 50, 100 and 150."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools = df[\"school\"].unique().tolist()\n",
    "\n",
    "interact(plot_wordcloud,school=schools,maxword=[20,50,100,150])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2  Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I would like to use LDA algorithm to generate 10 topics generated by variable $lemmatized\\_str$ per school. Then we shall guess what kinds of topics could be for each school."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for school in schools:\n",
    "    generate_topics(school)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(generate_topics,school=schools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 Sentiment Analysis\n",
    "\n",
    "### Question: Are there significant differences or categorical tendencies in the emotional biases of each school?\n",
    "### Sentiment Bar Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "test_df=pd.DataFrame()\n",
    "\n",
    "for school in schools:\n",
    "    test = copy.deepcopy(df.loc[df[\"school\"] == school])\n",
    "    test['compound'] = test['sentence_lowered'].apply(lambda x:analyzer.polarity_scores(x)['compound'])\n",
    "    test['sent_classification'] = test['compound'].apply(lambda x: 'positive' if x>=0.05 else 'negative' if x <=-0.05 else 'neutral')\n",
    "    test_new=pd.DataFrame({school:test.groupby('sent_classification')['compound'].count()/test.shape[0]})\n",
    "    test_df=test_df.append(test_new.T)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['school']=test_df.index\n",
    "test_df.plot(x='school', kind='bar', stacked=True,\n",
    "        title='Stacked Bar Graph by dataframe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Findings from the plot\n",
    "From the stacked bar plot I conclude that Capitalism, Empiricism and Rationalism talks mostly positive words while Continental and Feminism have most proportions for negative sentences. Phenomenology has the most percentages for neutral words comparing to other schools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kmeans Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=test_df.drop(['school'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3)\n",
    "kmeans.fit(X)\n",
    "y_kmeans = kmeans.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['school']\n",
    "y_kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X.iloc[:, 0], X.iloc[:, 1], c=y_kmeans, s=50, cmap='viridis')\n",
    "\n",
    "centers = kmeans.cluster_centers_\n",
    "plt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Findings from Kmeans clustering\n",
    "\n",
    "As we can observe from the cluster result and scatter plot above, Continental, Stoicism, Nietzsche and Feminism are from the same group and it can be infered as negative class while Empiricism, Rationalism and Capitalism are from positive class. The rest of schools are from netural class. \n",
    "\n",
    "The kmeans clustering results are consistent with the stacked bar plot and we indeed confirm the classificaiton for schools' sentiments correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
